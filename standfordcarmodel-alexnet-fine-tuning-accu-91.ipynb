{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as transforms\n\nimport pandas as pd\n\nimport time\nimport os\nimport PIL.Image as Image\nfrom IPython.display import display\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T20:36:17.604601Z","iopub.execute_input":"2023-07-08T20:36:17.604927Z","iopub.status.idle":"2023-07-08T20:36:18.981203Z","shell.execute_reply.started":"2023-07-08T20:36:17.604865Z","shell.execute_reply":"2023-07-08T20:36:18.980377Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the data and transform\n\nFirst, lets create some transforms for our data and load the train/test data+labels from the folders.\n\nHere we are using 300x300 images with random horizontal flip, random rotation and normalization","metadata":{}},{"cell_type":"code","source":"dataset_dir = \"../input/car_data/car_data/\"\n\ntrain_transform = transforms.Compose([transforms.Resize((300, 300)),\n                                 transforms.RandomRotation(15),\n                                 transforms.RandomHorizontalFlip(),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\ntest_transform = transforms.Compose([transforms.Resize((300, 300)),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n\ndataset = torchvision.datasets.ImageFolder(root=dataset_dir+\"train\", transform = train_transform)\ntrainloader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle=True, num_workers = 2)\n\ndataset2 = torchvision.datasets.ImageFolder(root=dataset_dir+\"test\", transform = test_transform)\ntestloader = torch.utils.data.DataLoader(dataset2, batch_size = 32, shuffle=False, num_workers = 2)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T20:36:18.982404Z","iopub.execute_input":"2023-07-08T20:36:18.982872Z","iopub.status.idle":"2023-07-08T20:36:23.210875Z","shell.execute_reply.started":"2023-07-08T20:36:18.982818Z","shell.execute_reply":"2023-07-08T20:36:23.209985Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Model training function\n\nHere we train our model, after each epoch, we test the model on the test data to see how it's going","metadata":{}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, n_epochs = 5):\n    \n    losses = []\n    accuracies = []\n    \n    model.train()\n    for epoch in range(n_epochs):\n        since = time.time()\n        running_loss = 0.0\n        running_correct = 0.0\n        counter = 0\n        for i, data in enumerate(trainloader, 0):\n            \n            inputs, labels = data\n            \n            # Assign data to CUDA if available\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            optimizer.zero_grad()\n            counter += len(inputs)\n            \n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels) # We need to give the original propabilities instead of the final labels.\n            \n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            running_correct += (labels==predicted).sum().item()\n\n        epoch_duration = time.time()-since\n        epoch_loss = running_loss / counter\n        print(running_correct, counter)\n        epoch_acc = 100 * (running_correct / counter)\n        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n        \n        losses.append(epoch_loss)\n        accuracies.append(epoch_acc)\n        \n        scheduler.step(epoch_acc)\n        since = time.time()\n    print('Finished Training')\n    \n    return model, losses, accuracies","metadata":{"execution":{"iopub.status.busy":"2023-07-08T20:36:23.212467Z","iopub.execute_input":"2023-07-08T20:36:23.213074Z","iopub.status.idle":"2023-07-08T20:36:23.223700Z","shell.execute_reply.started":"2023-07-08T20:36:23.213001Z","shell.execute_reply":"2023-07-08T20:36:23.222555Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate on testing data\nThis function is called out after training on the training data. We then measure the accuracy of the model.","metadata":{}},{"cell_type":"code","source":"def eval_model(model):\n    correct = 0.0\n    total = 0.0\n    with torch.no_grad():\n        for i, data in enumerate(testloader, 0):\n            images, labels = data\n            \n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model_ft(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    test_acc = 100.0 * (correct / total)\n    print('Accuracy of the network on the test images: %d %%' % (\n        test_acc))\n    return test_acc\n\n\ndef eval_model_for_plot(model):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    num_samples = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for inputs, labels in testloader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            _, preds = torch.max(outputs, 1)\n\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n            num_samples += inputs.size(0)\n\n            all_preds.append(preds.cpu().numpy().tolist())\n            all_labels.append(labels.data.cpu().numpy())\n\n        test_loss = running_loss / num_samples\n        test_accuracy = running_corrects.double() / num_samples\n\n    all_preds = np.concatenate(all_preds)\n    all_labels = np.concatenate(all_labels)\n    accuracy = (all_preds == all_labels).astype(np.float32).mean()\n\n    return test_loss, test_accuracy, accuracy, all_preds, all_labels\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T20:36:23.225238Z","iopub.execute_input":"2023-07-08T20:36:23.225898Z","iopub.status.idle":"2023-07-08T20:36:23.239773Z","shell.execute_reply.started":"2023-07-08T20:36:23.225845Z","shell.execute_reply":"2023-07-08T20:36:23.238866Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model_ft = models.densenet161(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T20:36:23.241140Z","iopub.execute_input":"2023-07-08T20:36:23.241728Z","iopub.status.idle":"2023-07-08T20:36:26.008250Z","shell.execute_reply.started":"2023-07-08T20:36:23.241612Z","shell.execute_reply":"2023-07-08T20:36:26.007487Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.torch/models/densenet161-8d451a50.pth\n115730790it [00:01, 82133705.17it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"\nnum_ftrs = model_ft.classifier.in_features\n\n# replace the last fc layer with an untrained one (requires grad by default)\nmodel_ft.classifier = nn.Linear(num_ftrs, 196)\nmodel_ft = model_ft.to(device)\n\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n\nlrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T20:36:26.009678Z","iopub.execute_input":"2023-07-08T20:36:26.010274Z","iopub.status.idle":"2023-07-08T20:36:30.967503Z","shell.execute_reply.started":"2023-07-08T20:36:26.010143Z","shell.execute_reply":"2023-07-08T20:36:30.966500Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_ft, training_losses, training_accs, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T20:36:30.968728Z","iopub.execute_input":"2023-07-08T20:36:30.969008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model_ft.state_dict(), './AlexNetFineTurning')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As we can see the model reached 99% training accuracy by epoch 10.\n","metadata":{}},{"cell_type":"code","source":"# Plot the training accuracy\nplt.plot(training_accs)\nplt.title('Training Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# Plot the training losses\nplt.plot(training_losses, label='Training loss')\nplt.title('Training Losses')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axarr = plt.subplots(2,2, figsize = (12, 8))\naxarr[0, 0].plot(training_losses)\naxarr[0, 0].set_title(\"Training loss\")\naxarr[0, 1].plot(training_accs)\naxarr[0, 1].set_title(\"Training acc\")\naxarr[1, 0].plot(test_accs)\naxarr[1, 0].set_title(\"Test acc\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_model(model_ft)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc, accuracy, all_preds, all_labels = eval_model_for_plot(model_ft)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create scatter plot\nplt.scatter(np.arange(len(all_preds)), all_preds == all_labels, s=5)\nplt.title('Accuracy of each test image')\nplt.xlabel('Index of test image')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### View the missclassified Images","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nnames = list(pd.read_csv(\"../input/names.csv\", names = ['names'])['names'])\nnames.sort()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib.pyplot import figure\n\ndef getMisclassifiedImages(model):\n    count = 0\n    with torch.no_grad():\n        fig = figure(figsize=(10, 10))\n        for i, data in enumerate(testloader, 0):\n            images, labels = data\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model_ft(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            for i in range(0, len(predicted)):\n                if (predicted[i] != labels[i]):\n                    img = images[i].cpu().numpy().transpose((1, 2, 0))\n                    mean = np.array([0.485, 0.456, 0.406])\n                    std = np.array([0.229, 0.224, 0.225])\n                    img = std * img + mean\n                    plt.subplot(3, 2 , count + 1)\n                    plt.tight_layout()\n                    plt.title(\"Predicted : \" + str(names[predicted[i]]) + \"\\n\" + \"Actual : \" + str(names[labels[i]]) + \"\\n\")\n                    plt.imshow((img * 255).astype(np.uint8))\n                    plt.axis(\"off\")\n                    count += 1\n                    if (count == 6):\n                        break\n            if (count == 6):\n                break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"getMisclassifiedImages(model_ft)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_classes = 196\n\nconfusion_matrix = torch.zeros(nb_classes, nb_classes)\nwith torch.no_grad():\n    for i, (inputs, classes) in enumerate(testloader):\n        inputs = inputs.to(device)\n        classes = classes.to(device)\n        outputs = model_ft(inputs)\n        _, preds = torch.max(outputs, 1)\n        for t, p in zip(classes.view(-1), preds.view(-1)):\n                confusion_matrix[t.long(), p.long()] += 1\n\nprint(confusion_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nnb_classes = 196\nconfusion_matrix = np.zeros((nb_classes, nb_classes))\nwith torch.no_grad():\n    for i, (inputs, classes) in enumerate(testloader):\n        inputs = inputs.to(device)\n        classes = classes.to(device)\n        outputs = model_ft(inputs)\n        _, preds = torch.max(outputs, 1)\n        for t, p in zip(classes.view(-1), preds.view(-1)):\n                confusion_matrix[t.long(), p.long()] += 1\n\nplt.figure(figsize=(20,20))\n\n\ndf_cm = pd.DataFrame(confusion_matrix)\nheatmap = sns.heatmap(df_cm, annot=True,fmt=\"d\")\n\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\nheatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n\nplt.ylabel('True label', fontsize=15)\nplt.xlabel('Predicted label', fontsize=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}